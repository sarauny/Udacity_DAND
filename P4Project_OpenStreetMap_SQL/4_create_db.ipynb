{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b1b36100-24e7-45b6-b1a9-6555144c49a3"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "# from collections import defaultdict\n",
    "# import pprint\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import os\n",
    "import sqlite3\n",
    "# import sys\n",
    "# import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "99a02fd7-6f22-4a2a-86ff-c7dec5b0e227"
    }
   },
   "source": [
    "## 1. Convert from XML to CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c51e9a11-b31c-46e0-9829-71f17ae82b46"
    }
   },
   "source": [
    "I converted the XML file into CSV files with functions below, so that csv files can be easily imported to a SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4f6ec97e-405e-4910-b23f-dd12385508dc"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/sarauenoyama/AnacondaProjects/Udacity_DAND/P4Project_Resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4fd5177e-49fd-41d6-9c20-fcd8f3f16aae"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "OSMFILE = \"singapore.osm\"\n",
    "OSM_PATH = \"singapore.osm\"\n",
    "osm_file = open(OSMFILE, \"r\")\n",
    "db_filename = 'singapore.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "a3384fed-e578-4316-b839-2147c9948a97"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOSMFILE = \"create_sample_singapore.osm\"\\nOSM_PATH = \"create_sample_singapore.osm\"\\nosm_file = open(OSMFILE, \"r\")\\ndb_filename = \\'sample_singapore.db\\'\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "OSMFILE = \"create_sample_singapore.osm\"\n",
    "OSM_PATH = \"create_sample_singapore.osm\"\n",
    "osm_file = open(OSMFILE, \"r\")\n",
    "db_filename = 'sample_singapore.db'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "34a20b4b-a8da-4d85-ba19-242297671aaa"
    }
   },
   "outputs": [],
   "source": [
    "# the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "21f87d84-f7c1-4229-8a49-102a5fed8e35"
    }
   },
   "outputs": [],
   "source": [
    "tree = ET.parse(osm_file)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8320ea1b-8ab5-4bbb-b389-4ccdc585bd77"
    }
   },
   "outputs": [],
   "source": [
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0fd1e86f-b7bd-49a1-9125-e5fd487d94d5"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c090c24f-551d-4e89-a436-df0a89dbaa35"
    }
   },
   "outputs": [],
   "source": [
    "%run \"schema.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b3abb47a-552e-4053-9adf-7a50aedd3e18"
    }
   },
   "outputs": [],
   "source": [
    "SCHEMA = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b66d38c1-cfea-419e-9936-044eb375ead0"
    }
   },
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = {}\n",
    "    tags = {}  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "    if element.tag == 'node':\n",
    "        \n",
    "        for i in node_attr_fields:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "        \n",
    "        for tag in element.iter('tag'):\n",
    "            node_tags_attribs = {}\n",
    "            temp = LOWER_COLON.search(tag.attrib['k'])\n",
    "            is_p = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            \n",
    "            if is_p: # if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "                continue\n",
    "            else:\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                \n",
    "                if temp: # if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type and characters after the \":\" should be set as the tag key\n",
    "                    split_char = temp.group(1)\n",
    "                    split_index = tag.attrib['k'].index(split_char)\n",
    "                    \n",
    "                    node_tags_attribs['key'] = tag.attrib['k'][split_index+2:]\n",
    "                    node_tags_attribs['type'] = tag.attrib['k'][:split_index+1]\n",
    "                \n",
    "                else: # if the tag \"k\" value does not contains a \":\" \"regular\" should be set as the tag type\n",
    "                    node_tags_attribs['key'] = tag.attrib['k']\n",
    "                    node_tags_attribs['type'] = default_tag_type\n",
    "            tags.append(node_tags_attribs)\n",
    "            \n",
    "       \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        p = 0\n",
    "        \n",
    "        for i in way_attr_fields:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "            \n",
    "        for tag2 in element.iter('tag'):\n",
    "            way_tags_attribs = {}\n",
    "            temp = LOWER_COLON.search(tag2.attrib['k'])\n",
    "            is_p = PROBLEMCHARS.search(tag2.attrib['k'])\n",
    "            \n",
    "            if is_p: # if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "                continue\n",
    "            else:\n",
    "                way_tags_attribs['id'] = element.attrib['id']\n",
    "                way_tags_attribs['value'] = tag2.attrib['v']\n",
    "                \n",
    "                if temp: # if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type and characters after the \":\" should be set as the tag key\n",
    "                    split_char = temp.group(1)\n",
    "                    split_index = tag2.attrib['k'].index(split_char)\n",
    "                    \n",
    "                    way_tags_attribs['key'] = tag2.attrib['k'][split_index+2:]\n",
    "                    way_tags_attribs['type'] = tag2.attrib['k'][:split_index+1]\n",
    "                \n",
    "                else: # if the tag \"k\" value does not contains a \":\" \"regular\" should be set as the tag type\n",
    "                    way_tags_attribs['key'] = tag2.attrib['k']\n",
    "                    way_tags_attribs['type'] = default_tag_type\n",
    "            tags.append(way_tags_attribs)\n",
    "        \n",
    "        \n",
    "        for j in element.iter('nd'):\n",
    "            way_nodes_attribs = {}\n",
    "            way_nodes_attribs['id'] = element.attrib['id']    \n",
    "            way_nodes_attribs['node_id'] = j.attrib['ref']\n",
    "            way_nodes_attribs['position'] = p\n",
    "            p+=1\n",
    "            \n",
    "            way_nodes.append(way_nodes_attribs)\n",
    "    \n",
    "    \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "11cb334c-fac2-45d9-b0f1-efa5eee52cd2"
    }
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "64b2681f-7250-42e2-a45e-0b7712245bce"
    }
   },
   "outputs": [],
   "source": [
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6ed0a072-6f55-48ce-b02c-7c0c3d82ca89"
    }
   },
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "509bfeb1-068e-4a5f-ab6d-6625e7d978d0"
    }
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                                                                                    #\n",
    "# ================================================== #\n",
    "\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2143f4e0-7d45-4269-a3fa-40bde1c84a20"
    }
   },
   "outputs": [],
   "source": [
    " process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Create database from the supplied schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "schema_filename = 'data_wrangling_schema.sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCING DATABASE to be DELETED\n",
      "Creating schema\n"
     ]
    }
   ],
   "source": [
    "delete_db = True\n",
    "#FORCE DELETION of DB\n",
    "if delete_db:\n",
    "\tif os.path.exists(db_filename):\n",
    "\t\tprint (\"FORCING DATABASE to be DELETED\")\n",
    "\t\tos.remove(db_filename)\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    if db_is_new:\n",
    "        print 'Creating schema'\n",
    "        with open(schema_filename, 'rt') as f:\n",
    "            schema = f.read()\n",
    "        conn.executescript(schema) # Create db from the supplied schema\n",
    "    else:\n",
    "        print 'Database exists, assume schema does, too.'\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import CSV into SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filename = ['nodes.csv', 'nodes_tags.csv', 'ways.csv', 'ways_tags.csv', 'ways_nodes.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to singapore.db\n",
    "conn = sqlite3.connect(\"singapore.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create tables on singapore.db\n",
    "# Dictionary of instructions per file\n",
    "# \"OR IGNORE\" : to avoid: sqlite3.IntegrityError: UNIQUE constraint failed: \n",
    "\n",
    "SQL = {}\n",
    "SQL[\"nodes.csv\"] = \"\"\"INSERT OR IGNORE INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) values (:id, :lat, :lon, :user, :uid, :version, :changeset, :timestamp)\"\"\"\n",
    "\n",
    "#nodes_tags\n",
    "SQL[\"nodes_tags.csv\"] = \"\"\"INSERT OR IGNORE INTO nodes_tags (id, key, value, type) values (:id, :key, :value, :type) \"\"\"\n",
    "\n",
    "#ways\n",
    "SQL[\"ways.csv\"] = \"\"\"INSERT OR IGNORE INTO ways (id, user, uid, version, changeset, timestamp) values (:id, :user, :uid, :version, :changeset, :timestamp)  \"\"\"\n",
    "\n",
    "#ways_tags\n",
    "SQL[\"ways_tags.csv\"] = \"\"\"INSERT OR IGNORE INTO ways_tags (id, key, value, type) values (:id, :key, :value, :type) \"\"\"\n",
    "\n",
    "#ways_nodes\n",
    "SQL[\"ways_nodes.csv\"] = \"\"\"INSERT OR IGNORE INTO ways_nodes (id, node_id, position) values (:id, :node_id, :position)  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes.csv\n",
      "INSERT OR IGNORE INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) values (:id, :lat, :lon, :user, :uid, :version, :changeset, :timestamp)\n",
      "nodes_tags.csv\n",
      "INSERT OR IGNORE INTO nodes_tags (id, key, value, type) values (:id, :key, :value, :type) \n",
      "ways.csv\n",
      "INSERT OR IGNORE INTO ways (id, user, uid, version, changeset, timestamp) values (:id, :user, :uid, :version, :changeset, :timestamp)  \n",
      "ways_tags.csv\n",
      "INSERT OR IGNORE INTO ways_tags (id, key, value, type) values (:id, :key, :value, :type) \n",
      "ways_nodes.csv\n",
      "INSERT OR IGNORE INTO ways_nodes (id, node_id, position) values (:id, :node_id, :position)  \n"
     ]
    }
   ],
   "source": [
    "for x in data_filename:\n",
    "\tprint x\n",
    "\twith open(x, 'rt') as csv_file:\n",
    "\t    csv_reader = csv.DictReader(csv_file)\n",
    "\t    print SQL[x]\n",
    "\t    \n",
    "\t    with sqlite3.connect(db_filename) as conn:\n",
    "\t    \tconn.text_factory = str\n",
    "\t        cursor = conn.cursor()\n",
    "\t        cursor.executemany(SQL[x], csv_reader)\n",
    "\t        conn.commit()\n",
    "\t    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
