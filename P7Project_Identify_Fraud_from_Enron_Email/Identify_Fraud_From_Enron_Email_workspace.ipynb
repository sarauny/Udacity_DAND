{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load poi_id.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Data Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the all data\n",
    "## Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns: 21\n",
      "name of the columns:\n",
      "Index([u'bonus', u'deferral_payments', u'deferred_income', u'director_fees', u'email_address',\n",
      "       u'exercised_stock_options', u'expenses', u'from_messages', u'from_poi_to_this_person',\n",
      "       u'from_this_person_to_poi', u'loan_advances', u'long_term_incentive', u'other', u'poi',\n",
      "       u'restricted_stock', u'restricted_stock_deferred', u'salary', u'shared_receipt_with_poi',\n",
      "       u'to_messages', u'total_payments', u'total_stock_value'],\n",
      "      dtype='object')\n",
      "number of non pois / pois: 128 / 18\n"
     ]
    }
   ],
   "source": [
    "# data overview\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.T\n",
    "number_of_non_poi, number_of_poi = df['poi'].value_counts()\n",
    "print \"number of columns:\", len(df.columns)\n",
    "print \"name of the columns:\\n\", df.columns\n",
    "print \"number of non pois / pois:\", number_of_non_poi, '/', number_of_poi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in data\n",
      "poi                            0\n",
      "total_stock_value             20\n",
      "total_payments                21\n",
      "email_address                 35\n",
      "restricted_stock              36\n",
      "exercised_stock_options       44\n",
      "salary                        51\n",
      "expenses                      51\n",
      "other                         53\n",
      "to_messages                   60\n",
      "shared_receipt_with_poi       60\n",
      "from_messages                 60\n",
      "from_poi_to_this_person       60\n",
      "from_this_person_to_poi       60\n",
      "bonus                         64\n",
      "long_term_incentive           80\n",
      "deferred_income               97\n",
      "deferral_payments            107\n",
      "restricted_stock_deferred    128\n",
      "director_fees                129\n",
      "loan_advances                142\n",
      "Name: nan, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_features_list = df.columns\n",
    "nan_index = df.columns\n",
    "nan_columns = ['non_nan', 'nan', 'nan_poi','nan_non_poi', 'poi_nan_ratio', 'non_poi_nan_ratio']\n",
    "df_nan = pd.DataFrame(index=nan_index, columns=nan_columns)\n",
    "df_nan = df_nan.fillna(0)\n",
    "\n",
    "for i in all_features_list:\n",
    "    for j in df.index:\n",
    "        if df[i][j] == 'NaN':\n",
    "            df_nan['nan'][i]+=1\n",
    "            if df['poi'][j] == True:\n",
    "                \n",
    "                df_nan['nan_poi'][i]+=1\n",
    "            else:\n",
    "                df_nan['nan_non_poi'][i]+=1\n",
    "        else:\n",
    "            df_nan['non_nan'][i]+=1\n",
    "\n",
    "# poi_nan_ratio column\n",
    "for i in all_features_list:\n",
    "    if df_nan['nan_poi'][i] == 0:\n",
    "        df_nan['poi_nan_ratio'][i] == 'NaN'\n",
    "    else:\n",
    "        df_nan['poi_nan_ratio'][i] = round((df_nan['nan_poi'][i])*100.0/number_of_poi, 2)\n",
    "\n",
    "# non_poi_nan_ratio column\n",
    "for i in all_features_list:\n",
    "    if df_nan['nan_non_poi'][i] == 0:\n",
    "            df_nan['non_poi_nan_ratio'][i] == 'NaN'\n",
    "    else:\n",
    "        df_nan['non_poi_nan_ratio'][i] = round((df_nan['nan_non_poi'][i])*100.0/number_of_non_poi, 2)\n",
    "\n",
    "df_nan_1 = df_nan[['non_nan', 'nan']].sort_values(by=['nan'], ascending = True)\n",
    "df_nan_2 = df_nan[['poi_nan_ratio', 'non_poi_nan_ratio']].sort_values(by=['poi_nan_ratio'], ascending = True)\n",
    "\n",
    "\n",
    "print 'Number of missing values in data'       \n",
    "print df_nan_1['nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of missing values in POI / non-POIs\n",
      "                           poi_nan_ratio  non_poi_nan_ratio\n",
      "total_stock_value                      0                 15\n",
      "poi                                    0                  0\n",
      "email_address                          0                 27\n",
      "other                                  0                 41\n",
      "expenses                               0                 39\n",
      "total_payments                         0                 16\n",
      "salary                                 5                 39\n",
      "restricted_stock                       5                 27\n",
      "bonus                                 11                 48\n",
      "from_this_person_to_poi               22                 43\n",
      "from_messages                         22                 43\n",
      "shared_receipt_with_poi               22                 43\n",
      "to_messages                           22                 43\n",
      "from_poi_to_this_person               22                 43\n",
      "long_term_incentive                   33                 57\n",
      "exercised_stock_options               33                 29\n",
      "deferred_income                       38                 70\n",
      "deferral_payments                     72                 73\n",
      "loan_advances                         94                 97\n",
      "director_fees                        100                 86\n",
      "restricted_stock_deferred            100                 85\n"
     ]
    }
   ],
   "source": [
    "print 'Ratio of missing values in POI / non-POIs'     \n",
    "print df_nan_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAADmCAYAAAD2m94SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFGWzUj3K4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e22a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('figure', figsize=(6,2))\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "# plot the salary and the bonus data\n",
    "features_outliers = [\"salary\", \"bonus\"]\n",
    "data_outliers = featureFormat(data_dict, features_outliers)\n",
    "\n",
    "for point in data_outliers:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter(salary,bonus)\n",
    "\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: TOTAL 97343619.0\n"
     ]
    }
   ],
   "source": [
    "# find the key of outlier\n",
    "for key, value in data_dict.items():\n",
    "    if value['bonus'] == data_outliers.max():\n",
    "        print 'max:', key, data_outliers.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the outlier 'TOTAL'\n",
    "data_dict.pop('TOTAL', 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAADmCAYAAAA9QDrsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkIiIiNQdJUAiIiJSd5QAiYiISN35/+ryDkg3tDT3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110243b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# second plot\n",
    "data_outliers = featureFormat(data_dict, features_outliers)\n",
    "for point in data_outliers:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter(salary,bonus)\n",
    "    \n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people whose both bonus and salary are away from other data points\n",
      "['LAY KENNETH L', 'SKILLING JEFFREY K']\n",
      "people whose only bonus is away from other data points\n",
      "['LAVORATO JOHN J', 'BELDEN TIMOTHY N']\n",
      "people whose only bonus is away from other data points\n",
      "['WHALLEY LAWRENCE G', 'PICKERING MARK R', 'FREVERT MARK A']\n"
     ]
    }
   ],
   "source": [
    "outlier_bonus =5000000\n",
    "outlier_salary = 500000\n",
    "\n",
    "both_outlier = []\n",
    "for key, value in data_dict.items():\n",
    "    if value['bonus'] == 'NaN':\n",
    "        pass\n",
    "    elif value['bonus'] > outlier_bonus:\n",
    "        if value['salary'] > outlier_salary:\n",
    "            both_outlier.append(key)\n",
    "    else:\n",
    "        pass\n",
    "print 'people whose both bonus and salary are away from other data points'   \n",
    "print both_outlier\n",
    "\n",
    "bonus_outlier = []\n",
    "for key, value in data_dict.items():\n",
    "    if value['bonus'] == 'NaN':\n",
    "        pass\n",
    "    elif value['bonus'] > outlier_bonus:\n",
    "        if value['salary'] > outlier_salary:\n",
    "            pass\n",
    "        else:\n",
    "            bonus_outlier.append(key)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print 'people whose only bonus is away from other data points'       \n",
    "print bonus_outlier\n",
    "\n",
    "salary_outlier = []\n",
    "for key, value in data_dict.items():\n",
    "    if value['salary'] == 'NaN':\n",
    "        pass\n",
    "    elif value['salary'] > outlier_salary:\n",
    "        if value['bonus'] > outlier_bonus:\n",
    "            pass\n",
    "        else:\n",
    "            salary_outlier.append(key)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print 'people whose only bonus is away from other data points'       \n",
    "print salary_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LAY KENNETH L: True\n",
      "  SKILLING JEFFREY K: True\n",
      "     LAVORATO JOHN J: False\n",
      "    BELDEN TIMOTHY N: True\n",
      "  WHALLEY LAWRENCE G: False\n",
      "    PICKERING MARK R: False\n",
      "      FREVERT MARK A: False\n"
     ]
    }
   ],
   "source": [
    "# find poi/non-poi of outlier\n",
    "outlier_list = both_outlier + bonus_outlier + salary_outlier\n",
    "\n",
    "poi_outlier = []\n",
    "non_poi_outlier = []\n",
    "for key in outlier_list:\n",
    "    poi_value = df.get_value(index=key, col='poi')\n",
    "    if poi_value == True:\n",
    "        poi_outlier.append(key)\n",
    "        print '{:>20}: {}'.format(key, poi_value)\n",
    "    else:\n",
    "        non_poi_outlier.append(key)  \n",
    "        print '{:>20}: {}'.format(key, poi_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-pois / pois: 123 / 18\n"
     ]
    }
   ],
   "source": [
    "# remove the non-poi outlier\n",
    "for key in non_poi_outlier:\n",
    "    data_dict.pop(key, 0 )\n",
    "\n",
    "# total number of poi nd non-poi after outlier removal    \n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.T\n",
    "number_of_non_poi, number_of_poi = df['poi'].value_counts()\n",
    "print \"number of non-pois / pois:\", number_of_non_poi, '/', number_of_poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Try a Variety of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation would be done by StratifiedShuffleSplit, based on f1 score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def validate(features, labels):\n",
    "    '''\n",
    "    Ten-fold cross-validation with stratified sampling.\n",
    "    '''\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    sss = StratifiedShuffleSplit(labels, n_iter=10)\n",
    "    for train_index, test_index in sss:\n",
    "        \n",
    "        features = np.asarray(features)\n",
    "        labels = np.asarray(labels)\n",
    "        features_train, features_test = features[train_index], features[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        clf.fit(features_train, labels_train)\n",
    "        y_pred = clf.predict(features_test)\n",
    "        accuracy_scores.append(accuracy_score(labels_test, y_pred))\n",
    "        precision_scores.append(precision_score(labels_test, y_pred))\n",
    "        recall_scores.append(recall_score(labels_test, y_pred))\n",
    "        f1_scores.append(f1_score(labels_test, y_pred))\n",
    "\n",
    "    return np.mean(precision_scores), np.mean(recall_scores), np.mean(f1_scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "# all features initially available and the first feature is 'poi'\n",
    "features_list = list(all_features_list)\n",
    "\n",
    "# bring the 'poi' feature first on the list for later data process\n",
    "def poi_first(features_list):\n",
    "    poi_index = features_list.index('poi')\n",
    "    if poi_index == 0:\n",
    "        pass\n",
    "    else:\n",
    "        features_list[poi_index], features_list[0] = features_list[0], features_list[poi_index]\n",
    "\n",
    "poi_first(features_list)\n",
    "        \n",
    "# remove email address from all features\n",
    "features_list.remove('email_address')\n",
    "\n",
    "### Extract features and labels from dataset again with the new features_list\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# split data into train and test data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, precision, reacall and f1 scores of each classifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>()</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.196667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.293333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 clf  precision  recall  f1 score\n",
       "0                                                 ()   0.250000    0.30  0.253333\n",
       "1                                       GaussianNB()   0.191667    0.30  0.230000\n",
       "2  SVC(C=1.0, cache_size=200, class_weight=None, ...   0.216667    0.20  0.196667\n",
       "3  DecisionTreeClassifier(class_weight=None, crit...   0.283333    0.35  0.293333"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# loop over several models to find the best one [1][5]\n",
    "classifiers = [\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    svm.SVC(),\n",
    "    DecisionTreeClassifier()\n",
    "    ]\n",
    "\n",
    "def clf_df(classifiers, features, labels):\n",
    "    clf_col = ['clf', 'precision', 'recall', 'f1 score']\n",
    "    clf_df = pd.DataFrame(index=[], columns=clf_col)\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        precision, recall, f1score = validate(features, labels)\n",
    "        series = pd.Series([clf, precision, recall, f1score], index=clf_df.columns)\n",
    "        clf_df = clf_df.append(series, ignore_index = True)\n",
    "    return clf_df\n",
    "\n",
    "print 'accuracy, precision, reacall and f1 scores of each classifier'\n",
    "clf_df(classifiers, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the clf_df result, choose the best algorithm to predict poi / non-poi\n",
    "classifiers = [\n",
    "    AdaBoostClassifier(),\n",
    "    DecisionTreeClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features scaling is not needed with DecisionTreeClassifier() in general [3][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n### feature importances on decision tree classifier\\nclf.fit(features, labels)\\nFeatureImportances = clf.feature_importances_\\nFeatureImportances = sorted(FeatureImportances, reverse=True)\\nfeatures_list_rm_poi = list(features_list)\\nfeatures_list_rm_poi.pop(0)\\n\\nprint 'feature importances by order'\\nfor i, feat in enumerate(features_list_rm_poi):\\n    print feat, ':', FeatureImportances[i]\\n\""
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "### feature importances on decision tree classifier\n",
    "clf.fit(features, labels)\n",
    "FeatureImportances = clf.feature_importances_\n",
    "FeatureImportances = sorted(FeatureImportances, reverse=True)\n",
    "features_list_rm_poi = list(features_list)\n",
    "features_list_rm_poi.pop(0)\n",
    "\n",
    "print 'feature importances by order'\n",
    "for i, feat in enumerate(features_list_rm_poi):\n",
    "    print feat, ':', FeatureImportances[i]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>()</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.458571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 clf  precision  recall  f1 score\n",
       "0                                                 ()   0.383333    0.35  0.333333\n",
       "1  DecisionTreeClassifier(class_weight=None, crit...   0.445000    0.55  0.458571"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "from fractions import Fraction\n",
    "\n",
    "### new feature 1: portion of from/to poi messages within all from/to messages\n",
    "def computeFraction( poi_messages, all_messages ):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "   \"\"\"\n",
    "\n",
    "    fraction = 0.\n",
    "    if 'email_address' == 'NaN':\n",
    "        return 0\n",
    "    else:\n",
    "        if all_messages == 0 or all_messages == 'NaN':\n",
    "            fraction = 0\n",
    "        if poi_messages == 'NaN':\n",
    "            fraction = 0\n",
    "        else:\n",
    "            fraction = Fraction(poi_messages, all_messages)\n",
    "    return fraction\n",
    "\n",
    "\n",
    "for name in my_dataset:\n",
    "\n",
    "    data_point = my_dataset[name]\n",
    "\n",
    "    from_poi_to_this_person = data_point['from_poi_to_this_person']\n",
    "    to_messages = data_point['to_messages']\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    data_point['fraction_from_poi'] = fraction_from_poi\n",
    "\n",
    "    from_this_person_to_poi = data_point['from_this_person_to_poi']\n",
    "    from_messages = data_point['from_messages']\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    data_point['fraction_to_poi'] = fraction_to_poi\n",
    "\n",
    "# add new features to features_list\n",
    "features_list.extend(['fraction_from_poi', 'fraction_to_poi'])\n",
    "\n",
    "### Extract features and labels from dataset again with the new features_list\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# validation of the clf with new features\n",
    "clf_df(classifiers, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid search score\n",
      "           parameters  mean_validation_score                               cv_validation_scores\n",
      "0    {u'kbest__k': 1}               0.280952  [0.8, 0.0, 0.0, 0.666666666667, 0.0, 0.0, 0.66...\n",
      "1    {u'kbest__k': 2}               0.336905  [0.333333333333, 0.5, 0.0, 0.666666666667, 0.0...\n",
      "2    {u'kbest__k': 3}               0.347857  [0.5, 1.0, 0.0, 0.5, 0.5, 0.0, 0.5, 0.0, 0.4, ...\n",
      "3    {u'kbest__k': 4}               0.307857  [0.4, 0.666666666667, 0.0, 0.4, 0.571428571429...\n",
      "4    {u'kbest__k': 5}               0.283571  [0.333333333333, 0.666666666667, 0.0, 0.0, 0.5...\n",
      "5    {u'kbest__k': 6}               0.316429  [0.333333333333, 0.8, 0.4, 0.0, 0.285714285714...\n",
      "6    {u'kbest__k': 7}               0.227381  [0.0, 0.8, 0.285714285714, 0.0, 0.0, 0.0, 0.66...\n",
      "7    {u'kbest__k': 8}               0.264524  [0.0, 0.666666666667, 0.4, 0.0, 0.4, 0.0, 0.66...\n",
      "8    {u'kbest__k': 9}               0.280952  [0.0, 1.0, 0.333333333333, 0.0, 0.285714285714...\n",
      "9   {u'kbest__k': 10}               0.358333  [0.0, 0.666666666667, 0.333333333333, 0.0, 0.5...\n",
      "10  {u'kbest__k': 11}               0.469762  [0.5, 1.0, 0.4, 0.0, 0.571428571429, 0.5, 0.5,...\n",
      "11  {u'kbest__k': 12}               0.395952  [0.333333333333, 1.0, 0.4, 0.0, 0.666666666667...\n",
      "12  {u'kbest__k': 13}               0.378095  [0.333333333333, 1.0, 0.4, 0.0, 0.666666666667...\n",
      "13  {u'kbest__k': 14}               0.282857  [0.333333333333, 0.0, 0.285714285714, 0.0, 0.6...\n",
      "14  {u'kbest__k': 15}               0.324762  [0.4, 0.0, 0.4, 0.0, 0.8, 0.5, 0.5, 0.0, 0.666...\n",
      "15  {u'kbest__k': 16}               0.332143  [0.5, 0.0, 0.333333333333, 0.0, 0.666666666667...\n",
      "16  {u'kbest__k': 17}               0.364558  [0.571428571429, 0.666666666667, 0.4, 0.0, 0.8...\n",
      "17  {u'kbest__k': 18}               0.394048  [0.4, 0.666666666667, 0.333333333333, 0.0, 0.6...\n",
      "18  {u'kbest__k': 19}               0.257143  [0.333333333333, 0.666666666667, 0.33333333333...\n",
      "19  {u'kbest__k': 20}               0.358571  [0.0, 0.666666666667, 0.285714285714, 0.0, 0.8...\n",
      "20  {u'kbest__k': 21}               0.267381  [0.333333333333, 0.0, 0.285714285714, 0.0, 0.4...\n",
      "\n",
      "best parameters set\n",
      "{'kbest__k': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.39000000000000001, 0.55000000000000004, 0.42714285714285716)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "# select features for Decision Tree Classifier using SelectKBest, connecting with Pipeline \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# features_list and data for now\n",
    "# features_list\n",
    "features_list = list(all_features_list)\n",
    "features_list.remove('email_address')\n",
    "features_list.extend(['fraction_from_poi', 'fraction_to_poi'])\n",
    "poi_first(features_list)\n",
    "\n",
    "# data \n",
    "### Extract features and labels from dataset again with the new features_list\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "# kbest with pipeline\n",
    "n_features = np.arange(1, len(features_list))\n",
    "kbest = SelectKBest(f_classif)\n",
    "pipeline = Pipeline([('kbest', kbest), ('DT', DecisionTreeClassifier())])\n",
    "\n",
    "parameters = {\n",
    "    'kbest__k':n_features\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, scoring='f1', cv=10)\n",
    "\n",
    "grid_search.fit(features, labels)\n",
    "grid_scores = pd.DataFrame(grid_search.grid_scores_)\n",
    "\n",
    "print 'grid search score'\n",
    "pd.set_option('display.width', 100)\n",
    "print grid_scores\n",
    "\n",
    "print '\\nbest parameters set'\n",
    "best_k = grid_search.best_params_\n",
    "print best_k\n",
    "\n",
    "clf = grid_search\n",
    "validate(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restricted_stock_deferred: 35.6553029979\n",
      "        deferral_payments: 27.9683623999\n",
      "            from_messages: 26.081456944\n",
      "            director_fees: 25.7158047926\n",
      "              to_messages: 16.5121282726\n",
      "  from_this_person_to_poi: 15.7179606972\n",
      "        fraction_from_poi: 12.44860887\n",
      "                 expenses: 11.9468554363\n",
      "                    other: 11.7959775751\n",
      "            loan_advances: 9.89055426333\n",
      "           total_payments: 9.51420263834\n"
     ]
    }
   ],
   "source": [
    "# when k=11 for SelectKBest\n",
    "kbest = SelectKBest(f_classif, k=11)\n",
    "\n",
    "# remove labels('poi') from the features_list\n",
    "features_list_rm_poi = features_list\n",
    "features_list_rm_poi.remove('poi')\n",
    "\n",
    "features_df = pd.DataFrame(features, columns=features_list_rm_poi)\n",
    "labels_df = pd.DataFrame(labels)\n",
    "\n",
    "kbest.fit(features, labels)\n",
    "features_new = kbest.transform(features)\n",
    "kbest_features = features_df.columns[kbest.get_support(indices=True)].tolist()\n",
    "kbest_scores = kbest.scores_\n",
    "\n",
    "kbest_features = []\n",
    "for i in np.argsort(kbest_scores):\n",
    "    kbest_features.append(features_list_rm_poi[i])\n",
    "\n",
    "kbest_scores = list(kbest_scores)    \n",
    "kbest_scores = sorted(kbest_scores, reverse=True)\n",
    "\n",
    "# print 11 best features and its scores\n",
    "for i in range(11):\n",
    "    print '{:>25}: {}'.format(kbest_features[i], kbest_scores[i])\n",
    "\n",
    "# rewrite the features_list with the best_k best features \n",
    "features_list = ['poi'] + kbest_features[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data with new feature list\n",
    "### Extract features and labels from dataset again with the new features_list\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Tune Your Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall\n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "# [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarauenoyama/anaconda2/envs/DAND/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [9] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters set\n",
      "{'DT__criterion': 'entropy', 'DT__max_depth': None, 'DT__min_samples_leaf': 6, 'DT__min_samples_split': 20}\n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('kbest', SelectKBest(k=11, score_func=<function f_classif at 0x11048f2a8>)), ('DT', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'DT__criterion': ['gini', 'entropy'], 'DT__max_depth': [None, 5, 10, 15, 20], 'DT__min_samples_split': [2, 4, 6, 8, 10, 20], 'DT__min_samples_leaf': [2, 4, 6, 8, 10, 20]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# select features using SelectKBest and GridSearch CV, connecting them with pipeline [3][6][7]\n",
    "\n",
    "n_features = np.arange(1, len(features_list))\n",
    "kbest = SelectKBest(f_classif, k=11)\n",
    "pipeline = Pipeline([('kbest', kbest), ('DT', DecisionTreeClassifier())])\n",
    "\n",
    "parameters = {\n",
    "    'DT__criterion':['gini', 'entropy'], \n",
    "    'DT__min_samples_split':[2, 4, 6, 8, 10, 20],\n",
    "    'DT__max_depth':[None, 5, 10, 15, 20],\n",
    "    'DT__min_samples_leaf':[2, 4, 6, 8, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=10)\n",
    "\n",
    "grid_search.fit(features, labels)\n",
    "grid_search.grid_scores_\n",
    "\n",
    "print 'best parameters set'\n",
    "print grid_search.best_params_\n",
    "\n",
    "clf = grid_search\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47499999999999998, 0.55000000000000004, 0.48666666666666664)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_leaf=6, min_samples_split=20)\n",
    "validate(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Dump Your Classifier, dataset, and features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "from tester import dump_classifier_and_data\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=6,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.87436\tPrecision: 0.57564\tRecall: 0.45850\tF1: 0.51044\tF2: 0.47795\n",
      "\tTotal predictions: 14000\tTrue positives:  917\tFalse positives:  676\tFalse negatives: 1083\tTrue negatives: 11324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %load tester.py\n",
    "#!/usr/bin/pickle\n",
    "\n",
    "\"\"\" a basic script for importing student's POI identifier,\n",
    "    and checking the results that they get from it \n",
    " \n",
    "    requires that the algorithm, dataset, and features list\n",
    "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
    "    my_feature_list.pkl, respectively\n",
    "\n",
    "    that process should happen at the end of poi_id.py\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: scikit-learn. Choosing the right estimator. Retrieved from https://scikit-learn.org/stable/tutorial/machine_learning_map\n",
    "\n",
    "[2]: Medium. Why, How and When to Scale your Features. Retrieved from https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e\n",
    "\n",
    "[3]: scikit-learn. sklearn.tree.DecisionTreeClassifier. Retrieved from https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  \n",
    "\n",
    "[4]: data school. Comparing supervised learning algorithms. Retrieved from https://www.dataschool.io/comparing-supervised-learning-algorithms/\n",
    "\n",
    "[5]: scikit-learn. sklearn.model_selection.GridSearchCV. Retrieved from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "[6]: Medium. A brief view of machine learning pipeline in python. Retrieved from https://medium.com/@yanhann10/a-brief-view-of-machine-learning-pipeline-in-python-5f50b941fca8\n",
    "\n",
    "[7]: Quora. How do I properly use SelectKBest, GridSearchCV, and cross-validation in the sklearn package together?. Retrieved from https://www.quora.com/How-do-I-properly-use-SelectKBest-GridSearchCV-and-cross-validation-in-the-sklearn-package-together\n",
    "\n",
    "[8]: busigence. Hyperparameter Optimization and Why is it important?. Retrieved from http://busigence.com/blog/hyperparameter-optimization-and-why-is-it-important  \n",
    "\n",
    "[9]: programcreek. Python sklearn.model_selection.StratifiedShuffleSplit() Examples. Retrieved from https://www.programcreek.com/python/example/91149/sklearn.model_selection.StratifiedShuffleSplit  \n",
    "\n",
    "[10]: w3cub. sklearn.model_selection.StratifiedShuffleSplit. Retrieved from  http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.model_selection.stratifiedshufflesplit/#sklearn.model_selection.StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hereby confirm that this submission is my work. I have cited above the origins of any parts of the submission that were taken from Websites, books, forums, blog posts, github repositories, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must  match the input. Model n_features is 23 and  input n_features is 19 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-e6d6703bff9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpred_kf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarauenoyama/anaconda2/envs/DAND/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sarauenoyama/anaconda2/envs/DAND/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[0;34m\" match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\" input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must  match the input. Model n_features is 23 and  input n_features is 19 "
     ]
    }
   ],
   "source": [
    "# cross validation with KFold\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "kf = KFold(len(features), n_folds=2, shuffle = True)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "for train_indices, test_indices in kf:\n",
    "    features_train_kf = features[train_indices]\n",
    "    features_test_kf = features[test_indices]\n",
    "    labels_train_kf = labels[train_indices]\n",
    "    labels_test_kf = labels[test_indices]\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(features_train_kf, labels_train_kf)\n",
    "clf.score(features_test_kf, labels_test_kf)\n",
    "\n",
    "pred_kf = clf.predict(features_test)\n",
    "precision = precision_score(labels_test, pred_kf, average='binary')\n",
    "recall = recall_score(labels_test, pred_kf, average='binary')\n",
    "\n",
    "print '\\nscore:', score, 'precision:', precision, 'recall:', recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[0]\n",
      "[0 1]\n",
      "[2]\n",
      "[0 2]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# validation using kfold cross validation\n",
    "from sklearn.cross_validation import KFold \n",
    "\n",
    "kfold = KFold(3, n_folds=3, shuffle=True, random_state=1)\n",
    "\n",
    "for train, test in kfold:\n",
    "    print train\n",
    "    print test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
